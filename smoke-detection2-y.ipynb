{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "spark = SparkSession.builder.appName(\"RandomForestExample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your data is in CSV format\n",
    "file_path = \"smoke_detection_iot.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Fire Alarm'\n",
    "\n",
    "feature_cols = [col for col in df.columns if col != target_col]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `PM1`.`0` cannot be resolved. Did you mean one of the following? [`_c0`, `UTC`, `Temperature[C]`, `Humidity[%]`, `TVOC[ppb]`, `eCO2[ppm]`, `Raw H2`, `Raw Ethanol`, `Pressure[hPa]`, `PM1`.`0`, `PM2`.`5`, `NC0`.`5`, `NC1`.`0`, `NC2`.`5`, `CNT`, `Fire Alarm`].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pc\\Big data\\smoke-detection2.ipynb Cellule 4\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pc/Big%20data/smoke-detection2.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m train_data, test_data \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mrandomSplit([\u001b[39m0.8\u001b[39m, \u001b[39m0.2\u001b[39m], seed\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pc/Big%20data/smoke-detection2.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pc/Big%20data/smoke-detection2.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mfit(train_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/Big%20data/smoke-detection2.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Make predictions\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pc/Big%20data/smoke-detection2.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtransform(test_data)\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\ml\\base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(params)\u001b[39m.\u001b[39m_fit(dataset)\n\u001b[0;32m    204\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(dataset)\n\u001b[0;32m    206\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(params)\n\u001b[0;32m    210\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\ml\\pipeline.py:132\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(stage, Transformer):\n\u001b[0;32m    131\u001b[0m     transformers\u001b[39m.\u001b[39mappend(stage)\n\u001b[1;32m--> 132\u001b[0m     dataset \u001b[39m=\u001b[39m stage\u001b[39m.\u001b[39;49mtransform(dataset)\n\u001b[0;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# must be an Estimator\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     model \u001b[39m=\u001b[39m stage\u001b[39m.\u001b[39mfit(dataset)\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\ml\\base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(params)\u001b[39m.\u001b[39m_transform(dataset)\n\u001b[0;32m    261\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(dataset)\n\u001b[0;32m    263\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mParams must be a param map but got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(params))\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\ml\\wrapper.py:398\u001b[0m, in \u001b[0;36mJavaTransformer._transform\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_java_obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 398\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrame(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_java_obj\u001b[39m.\u001b[39;49mtransform(dataset\u001b[39m.\u001b[39;49m_jdf), dataset\u001b[39m.\u001b[39msparkSession)\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `PM1`.`0` cannot be resolved. Did you mean one of the following? [`_c0`, `UTC`, `Temperature[C]`, `Humidity[%]`, `TVOC[ppb]`, `eCO2[ppm]`, `Raw H2`, `Raw Ethanol`, `Pressure[hPa]`, `PM1`.`0`, `PM2`.`5`, `NC0`.`5`, `NC1`.`0`, `NC2`.`5`, `CNT`, `Fire Alarm`]."
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=target_col, numTrees=10)\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[assembler, rf])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Fit the model\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=target_col, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
